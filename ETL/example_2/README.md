# ğŸ“¦ Multi-Format ETL Pipeline (CSV, JSON, XML)

## ğŸš€ Project Overview

This project demonstrates the implementation of a structured ETL
(Extract, Transform, Load) pipeline capable of processing data from
multiple file formats including:

-   CSV
-   JSON
-   XML

The pipeline consolidates heterogeneous data sources into a unified
tabular format using Python and Pandas, simulating real-world data
engineering workflows.

------------------------------------------------------------------------

## ğŸ—ï¸ Architecture Design

### 1ï¸âƒ£ Data Acquisition

Download source files:

``` bash
wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip
unzip source.zip
```

For extended practice:

``` bash
wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip
```

------------------------------------------------------------------------

## ğŸ› ï¸ Technology Stack

-   Python 3.11+
-   Pandas (data transformation)
-   XML parsing library
-   Glob (file discovery)
-   Datetime (logging timestamps)

Install required dependency:

``` bash
python3.11 -m pip install pandas
```

------------------------------------------------------------------------

## ğŸ”„ ETL Workflow

### ğŸ”¹ Extract

-   Detect file formats dynamically using `glob`
-   Parse:
    -   `.csv` via Pandas
    -   `.json` via Pandas
    -   `.xml` via xml parsing library
-   Load extracted data into Pandas DataFrames

### ğŸ”¹ Transform

-   Standardize column names
-   Normalize data types
-   Handle missing values
-   Convert data into a consistent schema

### ğŸ”¹ Load

-   Merge cleaned datasets
-   Export unified dataset
-   Log execution timestamp using `datetime`

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ csv_files/
    â”‚   â”œâ”€â”€ json_files/
    â”‚   â”œâ”€â”€ xml_files/
    â”œâ”€â”€ etl_script.py
    â”œâ”€â”€ logs.txt
    â””â”€â”€ README.md

------------------------------------------------------------------------

## ğŸ“ˆ Engineering Capabilities Demonstrated

-   Multi-format data ingestion
-   Schema normalization
-   Modular ETL design
-   Logging and traceability
-   Automated file handling
-   Production-style scripting practices

------------------------------------------------------------------------

## ğŸ¯ Real-World Applications

This ETL approach reflects real-world scenarios such as:

-   Enterprise data integration
-   Financial data consolidation
-   Business intelligence pipelines
-   Data lake ingestion preprocessing

------------------------------------------------------------------------

## ğŸš€ Execution

``` bash
python etl_script.py
```

------------------------------------------------------------------------

This project showcases practical data engineering skills aligned with
industry standards, emphasizing automation, reproducibility, and clean
data pipeline design.
